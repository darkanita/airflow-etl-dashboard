# âœˆï¸ ETL con Apache Airflow, SQLite y Streamlit

Proyecto educativo para aprender a construir pipelines ETL usando Apache Airflow, almacenar datos en SQLite y visualizarlos en un dashboard interactivo con Streamlit.

---

## ğŸ§  Â¿QuÃ© hace este proyecto?

âœ… Extrae un CSV pÃºblico con datos de vuelos  
âœ… Transforma los datos usando `pandas` (formato largo)  
âœ… Carga los datos en una base de datos SQLite  
âœ… Visualiza la informaciÃ³n con Streamlit (grÃ¡ficos y tabla interactiva)  

---

## ğŸ› ï¸ TecnologÃ­as usadas

- [Apache Airflow 2.10.5](https://airflow.apache.org/)
- Python 3.10
- Pandas
- SQLite
- Streamlit
- Docker + Docker Compose

---

## ğŸ—‚ï¸ Estructura del proyecto

```plaintext
airflow-etl-sqlite-streamlit/
â”œâ”€â”€ dags/                  # DAG principal de Airflow
â”‚   â””â”€â”€ etl_airtravel.py
â”œâ”€â”€ scripts/               # Scripts de ETL
â”‚   â”œâ”€â”€ extract.py
â”‚   â”œâ”€â”€ transform.py
â”‚   â””â”€â”€ load.py
â”œâ”€â”€ dashboard/             # App de Streamlit
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ data/                  # CSVs y base de datos SQLite generada
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ requirements.txt       # Dependencias para Streamlit
â””â”€â”€ README.md
```

## ğŸš€ CÃ³mo ejecutar el proyecto

### âœ… OpciÃ³n 1: Ejecutar **localmente con Docker**

1. Clona el repositorio:

```bash
git clone https://github.com/tu-usuario/etl-airflow-sqlite-streamlit.git
cd etl-airflow-sqlite-streamlit
```

2. Levanta Apache Airflow:
```bash
docker-compose up airflow-init
docker-compose up
```

3. Abre Airflow en http://localhost:8080
   Usuario: airflow | ContraseÃ±a: airflow

4. Corre el dashboard de Streamlit:

```bash
pip install -r requirements.txt
streamlit run dashboard/app.py
```

### ğŸ’» OpciÃ³n 2: Ejecutar en GitHub Codespaces
Este proyecto estÃ¡ preparado con un entorno .devcontainer para ejecutarse directamente en la nube sin necesidad de configuraciÃ³n local.

#### ğŸ“¦ Â¿QuÃ© se instala automÃ¡ticamente?
* Python 3.10
* Apache Airflow 2.10.5
* Streamlit + pandas + matplotlib
* SQLite
* Carpetas preconfiguradas (/data, /scripts, /dashboard)

#### ğŸ§­ Pasos para usar Codespaces
1. Entra a tu repositorio en GitHub
2. Haz clic en: Code â†’ Open with Codespaces â†’ New codespace
3. Espera que se construya el entorno (~2â€“3 minutos)
4. En el terminal del Codespace:

### ğŸ” Crea el usuario de Airflow:
```bash
airflow users create \
  --username airflow \
  --firstname Air \
  --lastname Flow \
  --role Admin \
  --email airflow@example.com \
  --password airflow
```

### ğŸš€ Inicia Airflow:
```bash
airflow webserver --port 8080 &
airflow scheduler &
```
5. Abre el puerto 8080 (Airflow UI) desde el menÃº de puertos de Codespaces
6. En otra terminal, corre el dashboard de Streamlit:
   
```bash
streamlit run dashboard/app.py
```
7. Abre el puerto 8501 para ver el dashboard

ğŸ“Š Â¿QuÃ© muestra el dashboard?
- ğŸ“‹ Tabla interactiva filtrable por aÃ±o
- ğŸ“ˆ GrÃ¡fico de lÃ­neas por mes
- ğŸ“Š GrÃ¡fico de barras comparativo
- Layout responsive (tabla arriba, grÃ¡ficos en dos columnas)

## ğŸ“„ Licencia
Este proyecto estÃ¡ bajo la licencia MIT.
Puedes usarlo, modificarlo y compartirlo libremente con atribuciÃ³n.

## âœ¨ Autor
Desarrollado por @darkanita
Con â¤ï¸ para enseÃ±ar y aprender ciencia de datos, pipelines y visualizaciÃ³n.

